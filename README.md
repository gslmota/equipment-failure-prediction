# Failure Prediction API & Streamlit Dashboard

This repository provides a production-ready **Failure Prediction API**, built with **FastAPI**, and an accompanying **Streamlit** dashboard for exploring and visualizing predictions. The machine learning model is trained and managed via Python scripts and pipelines in the `training/` folder, with artifacts persisted in `training/artifacts/`.

---

## ğŸ—‚ï¸ Repository Structure

```
failure-prediction-api/
â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”œâ”€â”€ controllers/          # Request handlers (health, predict, train)
â”‚   â”œâ”€â”€ domain/               # Core entities and business models
â”‚   â”œâ”€â”€ repositories/         # Data access layer (model loading/saving)
â”‚   â”œâ”€â”€ routes/               # FastAPI route definitions
â”‚   â”œâ”€â”€ services/             # Business logic (inference & training)
â”‚   â”œâ”€â”€ utils/                # Utility functions (feature engineering, sequence helpers)
â”‚   â”œâ”€â”€ dependencies.py       # Global dependency declarations
â”‚   â”œâ”€â”€ main.py               # FastAPI app instantiation
â”‚   â””â”€â”€ Dockerfile            # Docker image spec for API
â”œâ”€â”€ streamlit_app/            # Streamlit dashboard to consume the API
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ training/                 # Model training pipelines & scripts
â”‚   â”œâ”€â”€ pipelines/            # Data & training pipeline implementations
â”‚   â”œâ”€â”€ train_model.py        # Orchestrator for end-to-end training
â”‚   â””â”€â”€ artifacts/            # Generated artifacts (model, scaler, metadata)
â”œâ”€â”€ data.xlsx                 # Sample dataset (for local experimentation)
â”œâ”€â”€ tests/                    # Unit and integration tests
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ docker-compose.yml        # Local development with Docker Compose
â”œâ”€â”€ pyproject.toml            # Project metadata & dependencies (Poetry)
â””â”€â”€ README.md                 # This documentation
```

---

## ğŸš€ Features

* **FastAPI** endpoints for:

  * **Health check** (`GET /health`)
  * **Single prediction** (`POST /predict/single`)
  * **Model training** (`POST /train`)
* **Streamlit** front-end to interactively send data and visualize results.
* Modular design with clear separation:

  * Controllers, routes, services, repositories, utilities.
* **Poetry**-based dependency management.
* Dockerized for consistent local development and easy deployment.
* Test suite covering controllers, services, repositories, and utils.

---

## ğŸ› ï¸ Prerequisites

* [Docker & Docker Compose](https://docs.docker.com/compose/) (v2)
* [Poetry](https://python-poetry.org/) (optional, for local dev without Docker)
* PythonÂ 3.11+ (if running locally)

---

## âš™ï¸ Environment Setup

1. **Clone the repository**

   ```bash
   git clone https://github.com/gslmota/equipment-failure-prediction.git
   cd equipment-failure-prediction
   ```

2. **(Optional) Create `.env` file**
   Copy `.env.example` to `.env` (if provided) and adjust variables. At minimum, define:

   ```dotenv
   # .env
    PYTHONDONTWRITEBYTECODE=1
    TZ=America/Sao_Paulo
    TRAINING_DATA_PATH=/app/data.xlsx
    MODEL_ARTIFACTS_PATH=/app/training/artifacts
    LOG_LEVEL=INFO
    API_PORT=8000
   ```

3. **Install dependencies with Poetry** (for local development)

   ```bash
   poetry install
   ```

---

## ğŸ³ Running with Docker Compose

This is the recommended way for local development and testing:

```bash
docker compose up --build
```

* **API** will be available at `http://localhost:8000`
* **Swagger docs** at `http://localhost:8000/docs`
* **Streamlit** dashboard at `http://localhost:8501`

To tear down:

```bash
docker compose down
```

---

## ğŸ’» Running Locally (Without Docker)

1. Activate your Poetry shell:

   ```bash
   poetry shell
   ```

2. **Start the API**

   ```bash
   uvicorn api.main:app --reload --host 0.0.0.0 --port $API_PORT
   ```

3. **Start the Streamlit app** (in a separate terminal):

   ```bash
   export API_URL=\"http://localhost:$API_PORT/predict/single\"
   streamlit run streamlit_app/app.py
   ```

---

## ğŸ Debugging

* **API logs**: By default, Uvicorn prints logs. Use `LOG_LEVEL=debug` in your `.env` or pass `--log-level debug`:

  ```bash
  uvicorn api.main:app --reload --log-level debug
  ```

* **Breakpoints**: Insert `import pdb; pdb.set_trace()` in code, or use your IDEâ€™s debugger attached to the running process.

* **Rebuild Docker images** if you change dependencies or the Dockerfiles:

  ```bash
  docker compose build --no-cache api
  ```

---

## ğŸ§ª Testing

All tests are based on **pytest**.

Run the full suite:

```bash
pytest
```

* **Unit tests** live in `tests/unit/`
* **Integration tests** live in `tests/integration/`

You can run a specific test module:

```bash
pytest tests/unit/services/test_inference_service.py
```

---

## ğŸ“ Training a New Model

1. Prepare your data in `data.xlsx` (or point to a different source in your code).
2. Execute the training orchestration:

   ```bash
   python training/train_model.py --data-path data.xlsx
   ```
3. New artifacts (model, scaler, metadata) will be saved under `training/artifacts/`.
4. Restart the API to pick up the new model artifacts (if running as a service).

---

## ğŸ“ˆ Architecture & Design

1. **Controllers** handle HTTP requests and responses.
2. **Services** encapsulate business logic (feature engineering, training, inference).
3. **Repositories** manage persistence/loading of models and artifacts.
4. **Domain Entities** define data structures using Pydantic models.
5. **Utils** contain helper functions for sequence processing and feature pipelines.
6. **Streamlit App** consumes the API and visualizes predictions interactively.

---

## ğŸ“š Further Improvements

* Add CI/CD pipeline (GitHub Actions, GitLab CI) for automated tests and Docker builds.
* Integrate model versioning (e.g., MLflow).
* Add authentication to the API.
* Implement more advanced feature-tracking and monitoring.

---

## ğŸ“„ License

This project is released under the MIT License. See `LICENSE` for details.
